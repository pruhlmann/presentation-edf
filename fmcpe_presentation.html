<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Flow Matching Corrected Posterior Estimation (FMCPE)</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.5.0/dist/reset.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.5.0/dist/reveal.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.5.0/dist/theme/serif.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.5.0/plugin/highlight/monokai.css">
    <style>
        .reveal h1 { font-size: 2.2em; }
        .reveal h2 { font-size: 1.8em; }
        .reveal h3 { font-size: 1.4em; }
        .reveal ul { font-size: 0.75em; }
        .reveal ol { font-size: 0.75em; }
        .reveal li { margin-bottom: 0.3em; }
        .reveal p { font-size: 0.75em; }
        .reveal .slides section .fragment { opacity: 0; }
        .reveal .slides section .fragment.visible { opacity: 1; }
        .reveal .small { font-size: 0.7em; }
        .reveal .medium { font-size: 0.75em; }
        .reveal strong { color: #d33682; }
        .reveal em { font-style: italic; }
        .reveal .MathJax { font-size: 1em !important; }
        .reveal .MJXc-display { font-size: 1em !important; }
        .reveal mjx-container { font-size: 1em !important; }
        .reveal [data-auto-animate-target] {
          transition-property: transform, opacity !important;
          will-change: transform;
        }
        .reveal .slides section { text-align: left; }
        .reveal .slides section h1,
        .reveal .slides section h2,
        .reveal .slides section h3,
        .reveal .slides section h4,
        .reveal .slides section h5 { text-align: center; }
        .highlight-box {
            background-color: #f0f0f0;
            border-left: 4px solid #2aa198;
            padding: 15px;
            margin: 15px 0;
        }
        .remark-box {
            background-color: #fff;
            border: 2px solid #93a1a1;
            border-radius: 10px;
            padding: 15px;
            margin: 15px 0;
        }
        .equation {
            font-size: 0.9em;
            margin: 20px 0;
        }
        .title-slide {
            text-align: center !important;
        }
        .title-slide p {
            text-align: center !important;
        }
        .reveal {
            background-color: #ffffff !important;
        }
        .reveal .slides {
            background-color: #ffffff !important;
        }
    </style>
</head>
<body>
    <div class="reveal">
        <div class="slides">

            <!-- Title Slide -->
            <section class="title-slide">
                <h2>Flow Matching Corrected<br>Posterior Estimation (FMCPE)</h2>
                <p style="margin-top: 40px;">Pierre-Louis Ruhlmann</p>
                <p>Pedro L. Rodrigues, Michael Arbel, Florence Forbes</p>
                <p style="margin-top: 40px; font-size: 0.7em;">EDF workshop on Metamodels</p>
            </section>

            <!-- About Me Slide -->
            <section>
                <section data-auto-animate>
                    <h2 style="margin-bottom: 20px;">About me</h2>
                    <div class="medium"; style="align-items: center">
                        <ul>
                            <li>PhD student at Inria Grenoble (3rd year) </li>
                            <li>Statify/Thoth team</li>
                            <li>Research focus: Simulation-based inference </li>
                            <li>Supervisors: Pedro L. Rodrigues, Michael Arbel, Florence Forbes</li>
                        </ul>
                    </div>

                    <div style="display: flex; justify-content: center;">
                      <img data-id="statify-logo"
                           src="assets/statify.png"
                           alt="Statify Logo"
                           style="max-height: 150px; max-width: 550px; object-fit: contain;">
                    </div>
                </section>
                <section data-auto-animate>
                    <h2 style="margin-bottom: 10px;">About me</h2>
                    <div style="display: flex; flex-direction: column; align-items: center; justify-content: center; height: 55vh;">
                        <div style="margin-bottom: 3px; display;justify-content: center;">
                            <img src="assets/statify_team.jpeg" alt="Statify Team" style="max-height: 45vh; max-width: 95%; object-fit: contain;">
                        </div>
                        <div>
                            <img data-id="statify-logo" src="assets/statify.png" alt="Statify Logo" style="max-height: 150px; max-width: 550px; object-fit: contain;">
                        </div>
                    </div>
                </section>
            </section>

            <!-- Abstract -->
            <section>
                <h4>Abstract</h4>
                <div class="medium">
                    <p class="fragment">Simulation-based inference (SBI) methods enable likelihood-free Bayesian parameter estimation</p>
                    <p class="fragment"><strong>Problem:</strong> Model misspecification leads to biased posteriors and overconfident uncertainty quantification</p>
                    <p class="fragment"><strong>Our solution:</strong> Two-stage framework:
                        <ol>
                            <li>Use abundant parameter-simulation pairs \((\theta,x)\) to learn \(p(\theta|x)\)</li>
			    <li>Use a few <strong>calibration data</strong> to correct \(p(\theta|x)\) into \(p(\theta|y)\)</li>
                        </ol>
                    </p>
                    <p class="fragment">FMCPE recovers ground-truth parameters more accurately under severe simulator mismatch</p>
                </div>
            </section>

            <!-- Section 1: Introduction -->
            <section>
                <section>
                    <h2>Introduction</h2>
                </section>

                <section data-auto-animate>

    <h4>Statistical Inference</h4>

    <div data-id="bayes-rule" class="equation">
        <div class="r-stack">
            <div>
                $$p(\theta|x) = \frac{p(x|\theta)p(\theta)}{p(x)}$$
            </div>

            <!-- Second version already present but hidden -->
            <div style="opacity: 0;">
                $$p(\theta|x) = \frac{{\color{red}{p(x|\theta)}}p(\theta)}{p(x)}$$
            </div>
        </div>
    </div>

    <div class="fragment medium">
        <ul style="margin-top: 20px;">
            <li>\(p(\theta|x)\) - <strong>Posterior</strong>: what we want to compute</li>
            <li>\(p(x|\theta)\) - <strong>Likelihood</strong>: probability of data given parameters</li>
            <li>\(p(\theta)\) - <strong>Prior</strong>: initial beliefs about parameters</li>
            <li>\(p(x)\) - <strong>Evidence</strong>: normalizing constant</li>
        </ul>
    </div>

</section>
                <section data-auto-animate>
                    <h4>Statistical Inference</h4>
                    <div data-id="bayes-rule" class="equation">
                        <div class="r-stack">
                            <div>
                                $$p(\theta|x) = \frac{p(x|\theta)p(\theta)}{p(x)}$$
                            </div>
                            <div class="fragment" data-fragment-index="1">
				    $$p(\theta|x) = \frac{{\color{red}{p(x|\theta)}}p(\theta)}{p(x)}$$
                            </div>
                        </div>
                    </div>
                    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 30px; margin-top: 10px;">
                        <!-- Bayesian Inference Column -->
                        <div>
                            <h5 style="text-align: left; color: #2aa198; font-size: 0.85em;">Bayesian Inference</h5>
                            <div style="margin-top: 20px; font-size: 0.7em; text-align: left;">
                                <p class="fragment" data-fragment-index="1"><strong>Input:</strong> Model <span style="color: red;">likelihood</span> \(\color{red}{p(x|\theta)}\)</p>

                                <p class="fragment" data-fragment-index="2" style="margin-top: 20px;"><strong>Methods:</strong> MCMC, Variational Inference</p>

                                <p class="fragment" data-fragment-index="3" style="margin-top: 20px;"><strong>Output:</strong> Posterior \(p(\theta|x)\)</p>
                            </div>
                        </div>

                        <!-- SBI Column -->
                        <div>
                            <h5 style="text-align: left; color: #2aa198; font-size: 0.85em;">Simulation-Based Inference</h5>
                            <div style="margin-top: 20px; font-size: 0.7em; text-align: left;">
                                <p class="fragment" data-fragment-index="1"><strong>Input:</strong> Simulator \(S: \theta \mapsto x\)</p>

                                <p class="fragment" data-fragment-index="2" style="margin-top: 20px;"><strong>Methods:</strong> <span style="font-style: italic;">(See next section)</span></p>

                                <p class="fragment" data-fragment-index="3" style="margin-top: 20px;"><strong>Output:</strong> Posterior \(p(\theta|x)\)</p>
                            </div>
                        </div>
                    </div>

                    <p class="fragment" data-fragment-index="4" style="margin-top: 30px; text-align: center; font-size: 0.8em;">
                        <strong>Key difference:</strong> SBI works when likelihood is intractable
                    </p>
                </section>
<section>
                    <h4>Approximate Bayesian Computation (ABC)</h4>
                    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 30px; margin-top: 20px; font-size: 0.7em;">
                        <!-- Algorithm Steps Column -->
                        <div style="text-align: left;">
                            <h5 style="color: #2aa198; font-size: 1em; margin-bottom: 15px;">Algorithm</h5>
                            <div>
                                <p class="fragment" data-fragment-index="1", style="margin-bottom: 15px;    "><strong>Inputs:</strong> Simulator \(S\), \(\mathbf{y}_{\text{obs}}\), prior \(p(\theta)\), distance \(\rho\), threshold \(\epsilon\)</p>
                                <p class="fragment" data-fragment-index="2" style="margin-top: 15px;"><strong>For</strong> \(i = 1, \ldots, n\):</p>
                                <ol class="fragment" data-fragment-index="3" style="margin-left: 20px;">
                                    <li>Sample \(\theta_i \sim p(\theta)\)</li>
                                    <li class="fragment" data-fragment-index="4">Simulate \(\mathbf{x}_i = S(\theta_i)\)</li>
                                    <li class="fragment" data-fragment-index="5">Keep \(\theta_i\) if \(\rho(\mathbf{x}_i, \mathbf{y}_{\text{obs}}) < \epsilon\)</li>
                                </ol>
                            </div>
                        </div>

                        <!-- Python Code Column -->
                        <div style="text-align: left;">
                            <h5 style="color: #2aa198; font-size: 1em; margin-bottom: 15px;">Python Code</h5>
                            <div class="r-stack">
                                <pre class="fragment" data-fragment-index="1" style="margin: 0;"><code class="python" style="font-size: 0.85em;"># Inputs
S = simulator
y_obs = observed_data
prior = p_theta
rho = distance_function
epsilon = threshold</code></pre>

                                <pre class="fragment" data-fragment-index="2" style="margin: 0;"><code class="python" style="font-size: 0.85em;"># Inputs
S = simulator
y_obs = observed_data
prior = p_theta
rho = distance_function
epsilon = threshold

samples = []
for i in range(n):</code></pre>

                                <pre class="fragment" data-fragment-index="3" style="margin: 0;"><code class="python" style="font-size: 0.85em;"># Inputs
S = simulator
y_obs = observed_data
prior = p_theta
rho = distance_function
epsilon = threshold

samples = []
for i in range(n):
    # 1. Sample from prior
    theta_i = prior.sample()</code></pre>

                                <pre class="fragment" data-fragment-index="4" style="margin: 0;"><code class="python" style="font-size: 0.85em;"># Inputs
S = simulator
y_obs = observed_data
prior = p_theta
rho = distance_function
epsilon = threshold

samples = []
for i in range(n):
    # 1. Sample from prior
    theta_i = prior.sample()
    # 2. Simulate
    x_i = S(theta_i)</code></pre>

                                <pre class="fragment" data-fragment-index="5" style="margin: 0;"><code class="python" style="font-size: 0.85em;"># Inputs
S = simulator
y_obs = observed_data
prior = p_theta
rho = distance_function
epsilon = threshold

samples = []
for i in range(n):
    # 1. Sample from prior
    theta_i = prior.sample()
    # 2. Simulate
    x_i = S(theta_i)
    # 3. Keep if distance < epsilon
    if rho(x_i, y_obs) < epsilon:
        samples.append(theta_i)</code></pre>
                            </div>
                        </div>
                    </div>

                    <div class="medium fragment" data-fragment-index="6" style="margin-top: 30px;text-align: left;">
                        <p><strong>Limitations:</strong></p>
                        <ul>
                            <li>Poor scaling with dimension</li>
                            <li>Requires summary statistics</li>
                            <li>Not amortized</li>
                        </ul>
                    </div>

                    <div class="fragment" data-fragment-index="7" style="margin-top: 20px; font-size: 0.55em; color: #666; text-align: left;">
                        <p><strong>References:</strong> Beaumont et al. (2002), Sisson et al. (2018)</p>
                    </div>
                </section>

                <section>
                    <h4>Neural Posterior Estimation (NPE)</h4>
                    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 30px; margin-top: 20px; font-size: 0.7em;">
                        <!-- Algorithm Steps Column -->
                        <div style="text-align: left;">
                            <h5 style="color: #2aa198; font-size: 1em; margin-bottom: 15px;">Algorithm</h5>
                            <div>
                                <p class="fragment" data-fragment-index="1" style="margin-bottom: 15px;"><strong>Inputs:</strong> Simulator \(S\), budget \(N_{\text{train}}\), \(N_{\text{epochs}}\), neural approximator \(q_{\phi}\), summary net \(h_{\psi}\)</p>

                                <p class="fragment" data-fragment-index="2" style="margin-top: 15px;"><strong>Generate training data:</strong></p>
                                <p class="fragment" data-fragment-index="2" style="margin-left: 20px;">Sample \(\{(\theta_i, \mathbf{x}_i)\}_{i=1}^{N_{\text{train}}}\)</p>

                                <p class="fragment" data-fragment-index="3" style="margin-top: 15px;"><strong>For</strong> \(e = 1, \ldots, N_{\text{epochs}}\):</p>
                                <p class="fragment" data-fragment-index="4" style="margin-left: 20px;">Minimize KL divergence:</p>
                                <div class="fragment" data-fragment-index="4" style="margin-left: 20px; margin-top: 10px;">
                                    $$\mathcal{L}(\phi, \psi) = -\mathbb{E}[\log q_{\phi}(\theta | h_{\psi}(\mathbf{x}))]$$
                                </div>
                            </div>
                        </div>

                        <!-- Python Code Column -->
                        <div style="text-align: left;">
                            <h5 style="color: #2aa198; font-size: 1em; margin-bottom: 15px;">Python Code</h5>
                            <div class="r-stack">
                                <pre class="fragment" data-fragment-index="1" style="margin: 0;"><code class="python" style="font-size: 0.85em;"># Inputs
S = simulator
N_train = budget
N_epochs = num_epochs
q_phi = neural_approximator
h_psi = summary_net</code></pre>

                                <pre class="fragment" data-fragment-index="2" style="margin: 0;"><code class="python" style="font-size: 0.85em;"># Inputs
S = simulator
N_train = budget
N_epochs = num_epochs
q_phi = neural_approximator
h_psi = summary_net

# Generate training data
thetas = prior.sample(N_train)
xs = S(thetas)</code></pre>

                                <pre class="fragment" data-fragment-index="3" style="margin: 0;"><code class="python" style="font-size: 0.85em;"># Inputs
S = simulator
N_train = budget
N_epochs = num_epochs
q_phi = neural_approximator
h_psi = summary_net

# Generate training data
thetas = prior.sample(N_train)
xs = S(thetas)

# Training loop
for epoch in range(N_epochs):</code></pre>

                                <pre class="fragment" data-fragment-index="4" style="margin: 0;"><code class="python" style="font-size: 0.85em;"># Inputs
S = simulator
N_train = budget
N_epochs = num_epochs
q_phi = neural_approximator
h_psi = summary_net

# Generate training data
thetas = prior.sample(N_train)
xs = S(thetas)

# Training loop
for epoch in range(N_epochs):
    # Minimize KL divergence
    loss = -q_phi.log_prob(thetas, h_psi(xs)).mean()
    loss.backward()
    optimizer.step()</code></pre>
                            </div>
                        </div>
                    </div>

                    <div class="medium fragment" data-fragment-index="5" style="margin-top: 30px; text-align: left;">
                        <p><strong>Benefits:</strong> Amortized inference, no hand-crafted statistics needed</p>
                        <p style="margin-top: 10px;"><strong>Limitations:</strong> Prone to overfitting, sensitive to distribution shift</p>
                    </div>

                    <div class="fragment" data-fragment-index="6" style="margin-top: 20px; font-size: 0.55em; color: #666; text-align: left;">
                        <p><strong>References:</strong> Papamakarios & Murray (2016), Greenberg et al. (2019)</p>
                    </div>
                </section>
                <section>
                    <h4>Challenges in SBI</h4>
                    <div class="medium">
                        <ul>
                            <li class="fragment"><strong>Expensive simulations</strong> - High computational cost</li>
                            <li class="fragment"><strong>Exploit the simulator</strong> - In certain cases where the simulator is not a black box, we can leverage information (e.g. its gradient) to improve inference.</li>
                            <li class="fragment"><strong>Model misspecification</strong> - Main focus of this work.</li>
                        </ul>
                    </div>
                </section>

            </section>

            <!-- Section 2: Model Misspecification -->
            <section>
                <section>
                    <h2>Model Misspecification</h2>
                </section>

                <section>
                    <h4>Types of Misspecification and Objective</h4>
                    <div class="medium" style="color: inherit;">
                        <p><strong>Types of misspecification:</strong></p>
                        <ul style="margin-top: 20px;">
                            <li class="fragment"><strong style="color: inherit;">Simulator misspecification:</strong> Model assumptions are wrong or incomplete (e.g., missing physics)</li>
                            <li class="fragment"><strong style="color: inherit;">Prior misspecification:</strong> Prior distribution does not reflect true parameter ranges</li>
                            <li class="fragment"><strong style="color: inherit;">Observation noise:</strong> Noise model in likelihood is misspecified</li>
                        </ul>

                        <p class="fragment" style="margin-top: 30px;"><strong>Approaches to address misspecification:</strong></p>
                        <ul style="margin-top: 20px;">
                            <li class="fragment"><strong style="color: inherit;">Robustness:</strong> Ensemble methods or conservative posteriors</li>
                            <li class="fragment"><strong style="color: inherit;">Detection:</strong> Identify presence of misspecification</li>
                            <li class="fragment"><strong style="color: inherit;">Correction:</strong> Build new posterior accounting for discrepancy</li>
                        </ul>

                        <p class="fragment" style="margin-top: 30px; color: #d33682;"><strong>→ In this work, we focus on correcting simulator misspecification.</strong></p>
                    </div>
                </section>

                <section>
                    <h4>Misspecification of the simulator</h4>
                    <div class="medium">
                        <p>The data generating process \(\mathbf{y} \sim p^*\)</p>
                        <div class="equation">
                            $$ p^* \notin \left\lbrace p(\cdot|\mathbf{\theta}) \ \big\vert \ \mathbf{\theta} \in \mathbf{\Theta}\right\rbrace $$
                        </div>
                    </div>

                    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 30px; margin-top: 30px;">
                        <!-- Left Column - Model Equations -->
                        <div class="medium">
                            <h5 style="color: #2aa198; font-size: 1em; margin-bottom: 15px;">Example: Damped Pendulum</h5>

                            <div class="fragment" data-fragment-index="1">
                                <p><strong>High-fidelity model (ground truth):</strong></p>
                                <div class="equation" style="font-size: 0.95em;">
                                    $$\mathbf{y}(t) = e^{-\alpha t} A \cos(\omega_0 t) + \epsilon$$
                                </div>
                                <p style="margin-top: 10px;">Parameters: \(\theta = (\omega_0, A)\), damping \(\alpha \sim \mathcal{U}(0,1)\)</p>
                            </div>

                            <div class="fragment" data-fragment-index="2" style="margin-top: 25px;">
                                <p><strong>Low-fidelity simulator (misspecified):</strong></p>
                                <div class="equation" style="font-size: 0.95em;">
                                    $$\mathbf{x}(t) = A \cos(\omega_0 t) + \epsilon$$
                                </div>
                                <p style="margin-top: 10px; color: #d33682;"><strong>Missing damping term!</strong> \(\alpha = 0\)</p>
                            </div>
                            <div class="fragment" data-fragment-index="5" style="margin-top: 25px;">
                            <p> \(\rightarrow\) Even a small amount of misspecification can lead to highly biased posteriors !</p>
                            </div>
                        </div>

                        <!-- Right Column - Image -->
                        <div class="r-stack">
                        <div class="fragment" data-fragment-index="3" style="display: flex; align-items: center; justify-content: center;">
                            <img src="assets/pendulum.png" alt="Pendulum" style="max-width: 100%; height: auto;">
                        </div>
                        <div class="fragment" data-fragment-index="4" style="display: flex; align-items: center; justify-content: center;">
                            <img src="assets/npe_pendulum.png" alt="npe_pendulum" style="max-width: 100%; height: auto;">
                        </div>
                        </div>
                    </div>
                </section>

                <!--<section>-->
                <!--    <h4>Impact of model misspecification</h4>-->
                <!--    <div class="medium">-->
                <!--        <p>Even small misspecifications can lead to large errors in the posterior</p>-->
                <!--        <div style="margin-top: 30px;">-->
                <!--            <img src="assets/toy_plot.png" alt="Misspecification Impact" style="max-width: 95%; height: auto;">-->
                <!--        </div>-->
                <!--        <div class="equation" style="font-size: 0.8em; margin-top: 20px;">-->
                <!--            $$ \mathbf{\theta} \sim \mathcal{N}(0, 5), \ \mathbf{z}_{1:100} \sim \mathcal{N}(\mathbf{\theta}, \sigma + 1), \ S(\mathbf{\theta}) = (\text{mean}(\mathbf{z}_{1:100}), \text{var}(\mathbf{z}_{1:100})) $$-->
                <!--        </div>-->
                <!--    </div>-->
                <!--</section>-->
<section>
                    <h4>Data setting</h4>
                    <p style="font-size: 0.7em; margin-bottom: 30px;">There are two main ways to approach model misspecification in SBI:</p>
                    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 30px; font-size: 0.65em;">
                        <!-- Case 1 Column -->
                        <div class="fragment">
                            <h5 style="text-align: center; color: #2aa198; font-size: 1.1em; margin-bottom: 20px;">Case 1</h5>
                            <ul style="list-style: none; padding-left: 0;">
                                <li style="margin-bottom: 15px;"><strong>1. Simulation data:</strong><br>Access to simulated pairs \(\{\mathbf{\theta}_i, \mathbf{x}_i\}_{1:m}\)</li>
                                <li style="margin-bottom: 15px;"><strong>2. Observations:</strong><br>Independent observations \(\{\mathbf{y}_j\}_{1:n}\)<br><span style="font-size: 0.9em; font-style: italic;">(\(\mathbf{y}\) does not depend on \(\mathbf{\theta}\))</span></li>
                                <li style="margin-bottom: 15px;"><strong>3. Examples:</strong><br><span style="font-size: 0.9em;">(Add examples here)</span></li>
                            </ul>
                        </div>

                        <!-- Case 2 Column -->
                        <div class="fragment">
                            <h5 style="text-align: center; color: #2aa198; font-size: 1.1em; margin-bottom: 20px;">Case 2</h5>
                            <ul style="list-style: none; padding-left: 0;">
                                <li style="margin-bottom: 15px;"><strong>1. Simulation data:</strong><br>Access to simulated pairs \(\{\mathbf{\theta}_i, \mathbf{x}_i\}_{1:m}\)</li>
                                <li style="margin-bottom: 15px;"><strong>2. Calibration set:</strong><br>Few paired observations \(\{\mathbf{\theta}_j, \mathbf{y}_j\}_{1:n}\)<br><span style="font-size: 0.9em; font-style: italic;">(Multi-fidelity simulation, expensive ground truth)</span></li>
                                <li style="margin-bottom: 15px;"><strong>3. Examples:</strong><br><span style="font-size: 0.9em;">(Add examples here)</span></li>
                            </ul>
                        </div>
                    </div>
                    <p class="fragment" style="margin-top: 30px; color: #d33682; font-size: 0.7em;"><strong>→ In this work, we will focus on Case 2.</strong></p>
                </section>
            </section>

            <!-- Section 3: Existing Methods -->
            <section>
                <section>
                    <h2>Existing Methods</h2>
                </section>

                <section>
                    <h4>MF-NPE</h4>
                    <div class="medium">
                        <p>A first approach to correct the misspecification is to fine-tune the posterior estimator on the calibration set.</p>
                        <div class="fragment">
                            <p style="margin-top: 20px;">Assuming we have data from a low-fidelity simulator \((\mathbf{\theta},\mathbf{x}) \sim p(\mathbf{\theta})p(\mathbf{x}\mid \mathbf{\theta})\), we train a neural density estimator using:</p>
                            <div class="equation">
                                $$ \mathcal{L}_{NPE}(\phi) = \mathbb{E}_{\mathbf{\theta},\mathbf{x}} \left[ - \log q_{\phi}(\mathbf{\theta} | \mathbf{x}) \right] $$
                            </div>
                        </div>
                        <div class="fragment">
                            <p style="margin-top: 20px;">Then, using our small but precise calibration set \((\mathbf{\theta}_i, \mathbf{y}_i) \sim p(\mathbf{\theta},\mathbf{y})\), we fine-tune the posterior estimator using the same loss:</p>
                            <div class="equation">
                                $$ \mathcal{L}_{NPE}(\phi) = \mathbb{E}_{\mathbf{\theta},\mathbf{y}} \left[ - \log q_{\phi}(\mathbf{\theta} | \mathbf{y}) \right] $$
                            </div>
                        </div>
                    </div>
                </section>

                <section>
                    <h4>ROPE: Transporting \(\mathbf{y}\) to \(\mathbf{x}\)</h4>
                    <div class="medium">
                        <p>The ROPE method proposes to use optimal transport to match \(p^*(\mathbf{y})\) and \(p(\mathbf{x})\).</p>
                    </div>
                    <div style="font-size: 0.8em; margin-top: 20px;">
                        <p class="fragment"><strong>Input:</strong> Simulator \(S(\mathbf{\theta}, \epsilon)\), calibration data \(\{(\mathbf{\theta}^i, \mathbf{y}^i)\}_{i=1}^{N_c}\) and test set \(\{\mathbf{y}^i\}_{i=1}^{N_o}\)</p>
                        <p class="fragment"><strong>Step 1:</strong> Train n.n. \(h_{\omega}\) and density estimator \(q_{\phi}\)</p>
                        <div class="fragment equation">
                            $$ \mathcal{L}_{NPE}(\omega, \phi) = \mathbb{E}_{\mathbf{\theta},\mathbf{x}} \left[ - \log q_{\phi}\left(\mathbf{\theta} | h_{\omega}(\mathbf{x})\right) \right] $$
                        </div>
                        <p class="fragment"><strong>Step 2:</strong> Fine-tune \(h_{\omega}\) on calibration data \(\{(\mathbf{\theta}^i, \mathbf{y}^i)\}\) (Initialize \(g = h\))</p>
                        <div class="fragment equation">
                            $$ \mathcal{L}(\varphi) = \sum_{i=1}^{N_c} \Vert g_{\varphi}(\mathbf{y}^i) - \mathbb{E}_{\epsilon}[h_{\omega}\left(S(\mathbf{\theta}^i, \epsilon)\right]\Vert^2$$
                        </div>
                        <p class="fragment"><strong>Step 3:</strong> Transport \(h_{\omega}(\mathbf{x}^j)\) to \(g_{\psi}(\mathbf{y}^i)\)</p>
                        <p class="fragment"><strong>Output:</strong> Corrected posterior \(\tilde{p}(\mathbf{\theta} | \mathbf{y}) = \displaystyle\sum_{j}^{N_s} N_o P^*_{ij}q_{\phi}\left(\mathbf{\theta} | h_{\omega}(\mathbf{x}^j)\right)\)</p>
                    </div>
                </section>

                <section>
                    <h4>Key takeaways of ROPE</h4>
                    <div class="medium">
                        <ul>
                            <li class="fragment">Two main components: the fine-tuning of the summary statistic and the transport of the simulated data to the calibration set</li>
                            <li class="fragment">The correspondence between \(\mathbf{\theta}_i\) and \(\mathbf{y}^i\) is only used to define the OT cost</li>
                            <li class="fragment">The "test" set is used for the computation of the optimal transport. The method can't be applied to new data</li>
                            <li class="fragment">The hypothesis \(\mathbf{y} \perp \mathbf{\theta} \ \lvert \ \mathbf{x}\) is required to compute the posterior</li>
                        </ul>
                    </div>
                </section>
            </section>

            <!-- Section 4: Our Approach - Flow Matching -->
            <section>
                <section>
                    <h2>Our Approach</h2>
                    <h4>Flow Matching Corrected Posterior Estimation</h4>
                </section>

                <section>
                    <h4>Main Idea: Learn to Correct the Posterior</h4>
                    <div class="medium">
                        <p class="fragment"><strong>The Challenge:</strong></p>
                        <ul class="fragment">
                            <li>We have a posterior \(q_{\phi}(\theta|\mathbf{x})\) trained on cheap simulations \(\mathbf{x}\)</li>
                                <li>We have a small <strong>calibration set</strong> \(\mathcal{D}_{\text{cal}} = (\theta_i, \mathbf{y}_i)\) from the true process</li>
                            <li>Goal: Estimate \(p(\theta|\mathbf{y})\) by leveraging the calibration set and \(q_{\phi}(\theta|\mathbf{x})\) </li>
                        </ul>

                        <p class="fragment" style="margin-top: 30px;"><strong>Two step approach:</strong></p>
                        <ol class="fragment">
                                <li>Design a <strong>source distribution</strong> \(\pi(\mathbf{\theta} | \mathbf{y}) \) which acts as a first guess for the target \( p(\mathbf{\theta} | \mathbf{y})\)</li>
                            <li>Use <strong>Flow Matching</strong> to move samples from the source \(\pi(\mathbf{\theta} | \mathbf{y}) \) to \( p(\mathbf{\theta} | \mathbf{y})\)</li>
                        </ol>

                        <p class="fragment" style="margin-top: 30px;"><strong>Key Advantages:</strong></p>
                        <ul class="fragment">
                            <li>Leverages abundant simulations AND expensive calibration data efficiently</li>
                            <li>No independence assumption \(\mathbf{y} \perp \theta | \mathbf{x}\) required (as opposed to RoPE).</li>
                            <li>Can be plugged-in on top of any SBI methods that provides \(\pi(\mathbf{\theta} | \mathbf{x}) \)</li>
                        </ul>
                    </div>
                </section>
                <section>
                    <h4>Flow Matching</h4>
                    <div class="medium">
                        <p><strong>Objective:</strong> Match 2 distributions \(q_0,q_1\) via an ODE, i.e. learn a probability path \(p_t(\mathbf{x})\) with \(p_0 = q_0\) and \(p_1 = q_1\)</p>
                        <div class="equation">
                            $$ \frac{\mathrm{d}\psi_t(\mathbf{x})}{\mathrm{d}t} = u_t(\psi_t(\mathbf{x})) \qquad \psi_0(\mathbf{x}) = \mathbf{x} $$
                        </div>
                        <p class="fragment" style="margin-top: 20px;"><strong>Why:</strong> The vector field \(u(t, \mathbf{x}_t)\) and the probability path \(p_t\) verify the transport equation:</p>
                        <div class="fragment equation">
                            $$ \displaystyle\frac{\partial p_t(\mathbf{x})}{\partial t} = - \nabla \, . \, \left(u_t(\mathbf{x})p_t(\mathbf{x})\right)$$
                        </div>
                        <p class="fragment" style="margin-top: 20px;"><strong>How:</strong> We can regress the vector field with a neural network</p>
                        <div class="fragment equation">
                            $$ \mathcal{L}_{FM}(\phi) = \mathbb{E}_{t \sim \mathcal{U}[0,1]}\mathbb{E}_{\mathbf{x} \sim p_t} \left[\Vert u_{\phi}(t,\mathbf{x}) - u(t,\mathbf{x})\Vert^2\right]$$
                        </div>
                        <p class="fragment" style="color: red; margin-top: 15px;">→ We don't know \(u_t(\mathbf{x})\) !</p>
                    </div>
                </section>

                <section>
                    <h4>Conditional Flow Matching</h4>
                    <div class="medium">
                        <p><strong>Key Idea:</strong> Since we have access to samples from \(q_1\), we can condition the vector field on the target point \(\mathbf{x}_1 \sim q_1\)</p>
                        <div class="equation">
                            $$ p_t(\mathbf{x}_t) = \int q_1(\mathbf{x}_1)p_{t|1}(\mathbf{x}_t | \mathbf{x}_1) \mathrm{d} \mathbf{x}_1$$
                        </div>
                        <div class="fragment equation">
                            $$ p_{t = 0|1}(\mathbf{x} | \mathbf{x}_1) = \mathcal{N}(0,I) \qquad p_{t=1|1}(\mathbf{x} | \mathbf{x}_1) = \mathcal{N}\left(\mathbf{x}_1, \sigma_{\min}^2I\right)$$
                        </div>
                        <p class="fragment" style="margin-top: 20px;">The induced \(u_t(\mathbf{x} | \mathbf{x}_1)\) is available in closed form e.g.</p>
                        <div class="fragment equation">
                            $$ u_t(\mathbf{x}|\mathbf{x}_1) = \mathbf{x}_1 - \mathbf{x}$$
                        </div>
                        <p class="fragment" style="margin-top: 15px;">The loss becomes</p>
                        <div class="fragment equation">
                            $$ \mathcal{L}_{CFM}(\phi) = \mathbb{E}_{t \sim \mathcal{U}[0,1],\mathbf{x}_1 \sim q_1, \mathbf{x}_t \sim p_t(\mathbf{x}|\mathbf{x}_1)} \left[\Vert u_{\phi}(t,\mathbf{x}) - u_t(\mathbf{x}|\mathbf{x}_1)\Vert^2\right]$$
                        </div>
                        <p class="fragment" style="color: red; margin-top: 15px;">→ Same gradient as \(\mathcal{L}_{FM}\)</p>
                    </div>
                </section>

                <section>
                    <h4>FMCPE: Three Main Components</h4>
                    <div class="medium">
                        <ol style="margin-top: 30px;">
                            <li class="fragment" style="margin-bottom: 25px;">
                                <strong>Parameter space flow:</strong> Transport samples from source \(\pi(\theta|y)\) to target \(p(\theta|y)\)
                            </li>
                            <li class="fragment" style="margin-bottom: 25px;">
                                <strong>Source distribution construction:</strong> Design \(\pi(\theta|y)\) using NPE and learnable kernel
                                <div class="equation" style="font-size: 0.85em; margin-top: 10px;">
                                    $$\pi(\theta|y) = \int p(\theta|x)q(x|y)dx$$
                                </div>
                            </li>
                            <li class="fragment" style="margin-bottom: 25px;">
                                <strong>Joint optimization:</strong> Learn both flows together for improved robustness
                            </li>
                        </ol>
                    </div>
                </section>

                <section>
                    <h4>Component 1: Parameter Space Flow</h4>
                    <div class="medium">
                        <p class="fragment"><strong>Goal:</strong> Map samples from source \(\pi(\theta|y)\) to corrected posterior \(p(\theta|y)\)</p>

                        <div class="fragment" style="margin-top: 25px;">
                            <p><strong>Flow definition:</strong></p>
                            <div class="equation">
                                $$\frac{d\theta_t}{dt} = u_{\Theta}(t, \theta_t, y)$$
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 25px;">
                            <p><strong>Training objective:</strong> Conditional Flow Matching loss</p>
                            <div class="equation">
                                $$\mathcal{L}_{\Theta} = \mathbb{E}\left[\|u_{\Theta}(t, \theta_t, y) - (\theta_1 - \theta_0)\|^2\right]$$
                            </div>
                            <p style="font-size: 0.9em; margin-top: 10px;">where \(\theta_1 \sim p(\theta|y)\) (from calibration) and \(\theta_0 \sim \pi(\theta|y)\) (from source)</p>
                        </div>
                    </div>
                </section>

                <section>
                    <h4>Component 2: Source Distribution</h4>
                    <div class="medium">
                        <p class="fragment"><strong>Key insight:</strong> Use simulation-trained NPE \(p(\theta|x)\) with learned correction</p>

                        <div class="fragment" style="margin-top: 25px;">
                            <p><strong>Source construction:</strong></p>
                            <div class="equation">
                                $$\pi(\theta|y) = \int p(\theta|x)q(x|y)dx$$
                            </div>
                            <ul style="margin-top: 15px;">
                                <li>\(p(\theta|x)\): Pretrained NPE on cheap simulations (frozen)</li>
                                <li>\(q(x|y)\): Learnable kernel mapping \(y\) to simulator space</li>
                            </ul>
                        </div>

                        <div class="fragment" style="margin-top: 25px;">
                            <p><strong>Why this works:</strong> Bridges the gap between calibration data \(y\) and simulations \(x\)</p>
                        </div>
                    </div>
                </section>

                <section>
                    <h4>Component 3: Learning q(x|y)</h4>
                    <div class="medium">
                        <p class="fragment"><strong>Approach:</strong> Use Flow Matching to learn \(q(x|y)\)</p>

                        <div class="fragment" style="margin-top: 25px;">
                            <p><strong>Flow in simulation space:</strong></p>
                            <div class="equation">
                                $$\frac{dx_t}{dt} = u_{X}(t, x_t, y)$$
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 25px;">
                            <p><strong>Training data generation:</strong> For each calibration pair \((\theta_i, y_i)\):</p>
                            <ol style="margin-top: 10px; font-size: 0.9em;">
                                <li>Generate \(x_1 = S(\theta_i)\) using the simulator</li>
                                <li>Sample base \(x_0 \sim \mathcal{N}(y, \sigma^2 I)\)</li>
                                <li>Train flow to match \(x_0 \to x_1\)</li>
                            </ol>
                        </div>

                        <div class="fragment" style="margin-top: 25px;">
                            <p><strong>Result:</strong> \(q(x|y)\) learns to transport from observed space to simulator space</p>
                        </div>
                    </div>
                </section>

                <section>
                    <h4>Joint Training Algorithm</h4>
                    <div class="medium">
                        <p class="fragment"><strong>Key idea:</strong> Train both flows \(u_X\) and \(u_{\Theta}\) simultaneously</p>

                        <div class="fragment" style="margin-top: 20px;">
                            <p><strong>Training loop:</strong></p>
                            <div style="background-color: #f8f8f8; padding: 15px; border-radius: 5px; margin-top: 10px; font-size: 0.87em;">
                                <p style="margin-bottom: 10px;"><strong>For each minibatch:</strong></p>
                                <ol style="margin-left: 20px; line-height: 1.6;">
                                    <li>Sample \((\theta_1, y)\) from calibration set \(\mathcal{D}_{\text{cal}}\)</li>
                                    <li>Generate \(x_1 = S(\theta_1)\) using simulator</li>
                                    <li>Sample base points: \(x_0 \sim \mathcal{N}(y, \sigma^2 I)\)</li>
                                    <li>Map \(x_0\) to simulator space: \(\tilde{x} = T_X(x_0; y)\) using current \(u_X\)</li>
                                    <li>Sample from source: \(\theta_0 \sim p(\theta|\tilde{x})\) using pretrained NPE</li>
                                    <li>Compute flow matching losses for both flows:
                                        <div class="equation" style="font-size: 0.95em; margin: 10px 0;">
                                            $$\ell_X = \|u_X(t, x_t, y) - (x_1 - x_0)\|^2$$
                                            $$\ell_{\Theta} = \|u_{\Theta}(\tau, \theta_{\tau}, y) - (\theta_1 - \theta_0)\|^2$$
                                        </div>
                                    </li>
                                    <li>Update both \(u_X\) and \(u_{\Theta}\) using \(\mathcal{L} = \ell_X + \ell_{\Theta}\)</li>
                                </ol>
                            </div>
                        </div>

                        <p class="fragment" style="margin-top: 20px; color: #d33682;"><strong>→ Joint training ensures consistency between source and parameter flows</strong></p>
                    </div>
                </section>

                <section>
                    <h4 style="margin-bottom: 50px;">FMCPE Overview</h4>
                    <div style="display: grid; grid-template-columns: 1.1fr 1fr; gap: 10px; align-items: top; width: 150%; margin-left: -25%; margin-right: -25%;">
                        <!-- Schema column with r-stack -->
                        <div class="r-stack">
                            <img class="fragment fade-in-then-out" data-fragment-index="1" src="assets/schema_0.svg" alt="Schema step 0" style="width: 100%; height: auto;">
                            <img class="fragment fade-in-then-out" data-fragment-index="2" src="assets/schema_1.svg" alt="Schema step 1" style="width: 100%; height: auto;">
                            <img class="fragment fade-in-then-out" data-fragment-index="3" src="assets/schema_2.svg" alt="Schema step 2" style="width: 100%; height: auto;">
                            <img class="fragment fade-in-then-out" data-fragment-index="4" src="assets/schema_3.svg" alt="Schema step 3" style="width: 100%; height: auto;">
                            <img class="fragment fade-in" data-fragment-index="5" src="assets/schema_full.svg" alt="Schema full" style="width: 100%; height: auto;">
                        </div>
                        <!-- Algo column with r-stack -->
                        <div class="r-stack">
                            <img class="fragment fade-in-then-out" data-fragment-index="1" src="assets/algo_0.svg" alt="Algorithm step 0" style="width: 100%; height: auto;">
                            <img class="fragment fade-in-then-out" data-fragment-index="2" src="assets/algo_1.svg" alt="Algorithm step 1" style="width: 100%; height: auto;">
                            <img class="fragment fade-in-then-out" data-fragment-index="3" src="assets/algo_2.svg" alt="Algorithm step 2" style="width: 100%; height: auto;">
                            <img class="fragment fade-in-then-out" data-fragment-index="4" src="assets/algo_3.svg" alt="Algorithm step 3" style="width: 100%; height: auto;">
                            <img class="fragment fade-in" data-fragment-index="5" src="assets/algo_full.svg" alt="Algorithm full" style="width: 100%; height: auto;">
                        </div>
                    </div>
                </section>
            <!-- Results -->

                <section>
		<h4>Results</h4>
                    <div style="display: flex; justify-content: center; align-items: center; margin-top: 10px; width: 100%;">
                        <img src="assets/kde.svg" alt="KDE Results" style="width: 85%; height: auto;">
                    </div>
                </section>
            </section>


            <!-- Conclusion -->
            <section>
                <h2>Thank You!</h2>
                <div class="medium">
                    <p>Questions?</p>
                </div>
            </section>

            <!-- Appendix -->
            <section>
                <section>
                    <h2>Appendix</h2>
                </section>

                <section>
                    <h4>Common hypothesis</h4>
                    <div class="medium">
                        <p>In most settings, the error is assumed to be independent of \(\mathbf{\theta}\):</p>
                        <div class="equation">
                            $$ \mathbf{y} \perp \mathbf{\theta} \ \lvert \ \mathbf{x} $$
                        </div>
                        <p class="fragment" style="margin-top: 20px;">This is a necessary condition to express \(p\left( \mathbf{\theta} | \mathbf{y}  \right)\) using \(p\left( \mathbf{\theta} | \mathbf{x}  \right)\) and \(p\left( \mathbf{x} | \mathbf{y}  \right)\):</p>
                        <div class="fragment equation">
                            $$ p\left( \mathbf{\theta} | \mathbf{y}  \right) = \int_{\mathcal{X}} p\left( \mathbf{\theta} | \mathbf{x}  \right) p(\mathbf{x} | \mathbf{y})\mathrm{d}\mathbf{x} $$
                        </div>
                        <p class="fragment" style="margin-top: 20px; font-size: 0.9em;">In practice, this is not always true for various physical systems. The low-fidelity simulator might not depend on some of the parameters, using a lower dimensional \(\mathbf{\theta}\).</p>
                    </div>
                </section>

                <section>
                    <h4>NPE Loss Derivation from KL Divergence</h4>
                    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 30px; margin-top: 20px; font-size: 0.65em;">
                        <!-- Left Column -->
                        <div>
                            <p>We want to minimize the KL divergence for all \(\mathbf{x}\):</p>
                            <div class="equation fragment" style="font-size: 0.95em;">
                                $$\mathbb{E}_{p(\mathbf{x})}\left[\text{KL}(p(\theta|\mathbf{x}) \,||\, q_{\phi}(\theta|\mathbf{x}))\right]$$
                            </div>
                            <div class="equation fragment" style="font-size: 0.95em; margin-top: 10px;">
                                $$= \mathbb{E}_{p(\mathbf{x})}\mathbb{E}_{p(\theta|\mathbf{x})}\left[\log \frac{p(\theta|\mathbf{x})}{q_{\phi}(\theta|\mathbf{x})}\right]$$
                            </div>

                            <p class="fragment" style="margin-top: 20px;">Expanding the logarithm:</p>
                            <div class="equation fragment" style="font-size: 0.95em;">
                                $$= \mathbb{E}_{p(\mathbf{x})}\mathbb{E}_{p(\theta|\mathbf{x})}\left[\log p(\theta|\mathbf{x})\right]$$
                            </div>
                            <div class="equation fragment" style="font-size: 0.95em;">
                                $$- \mathbb{E}_{p(\mathbf{x})}\mathbb{E}_{p(\theta|\mathbf{x})}\left[\log q_{\phi}(\theta|\mathbf{x})\right]$$
                            </div>

                            <p class="fragment" style="margin-top: 20px;">First term does not depend on \(\phi\):</p>
                            <div class="equation fragment" style="font-size: 0.95em;">
                                $$\min_{\phi} \mathbb{E}_{p(\mathbf{x})}\left[\text{KL}(p \,||\, q_{\phi})\right]$$
                            </div>
                        </div>

                        <!-- Right Column -->
                        <div>
                            <p>Equivalent to maximizing:</p>
                            <div class="equation fragment" style="font-size: 0.95em;">
                                $$\max_{\phi} \mathbb{E}_{p(\mathbf{x})}\mathbb{E}_{p(\theta|\mathbf{x})}\left[\log q_{\phi}(\theta|\mathbf{x})\right]$$
                            </div>

                            <p class="fragment" style="margin-top: 20px;">Using joint distribution \(p(\theta, \mathbf{x}) = p(\mathbf{x}|\theta)p(\theta)\):</p>
                            <div class="equation fragment" style="font-size: 0.95em;">
                                $$= \max_{\phi} \mathbb{E}_{p(\theta, \mathbf{x})}\left[\log q_{\phi}(\theta|\mathbf{x})\right]$$
                            </div>

                            <p class="fragment" style="margin-top: 20px;">Approximate with samples:</p>
                            <div class="equation fragment" style="font-size: 0.95em;">
                                $$\mathcal{L}(\phi, \psi) = -\frac{1}{N}\sum_{i=1}^{N} \log q_{\phi}(\theta_i | h_{\psi}(\mathbf{x}_i))$$
                            </div>

                            <p class="fragment" style="margin-top: 20px;">where \((\theta_i, \mathbf{x}_i) \sim p(\theta)p(\mathbf{x}|\theta)\)</p>
                        </div>
                    </div>
                </section>
            </section>

        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.5.0/dist/reveal.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.5.0/plugin/notes/notes.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.5.0/plugin/markdown/markdown.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.5.0/plugin/highlight/highlight.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.5.0/plugin/math/math.js"></script>
    <script>
        Reveal.initialize({
            hash: true,
            controls: true,
            progress: true,
            center: true,
            transition: 'slide',
            slideNumber: true,
            math: {
                mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js',
                config: 'TeX-AMS_HTML-full',
            },
            plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath.MathJax3 ],
            autoAnimate: {
            // Prevents stretch/tear effects
            easing: 'ease-out',
            duration: 0.6,

            // This is the key line:
            autoAnimateUnmatched: false
          }
        });
    </script>
</body>
</html>
